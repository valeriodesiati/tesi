% % !TeX spellcheck = it_IT

\chapter{Tecnologie utilizzate}\label{sec:second_mpi}
In questo capitolo saranno descritte le tecnologie più rilevanti utilizzate nella realizzazione del progetto.

\section{Git}
\emph{Git} è un DVCS (Distributed Version Control Systems) gratuito, open source e distribuito, utilizzabile da riga di comando, che consente di effettuare il controllo versione per un progetto.\\
Data la sua natura “distribuita” \emph{Git} è basato su flussi di lavoro simultanei; quindi, diversi sviluppatori possono collaborare ad un progetto, ognuno con il proprio workflow.
\begin{figure}[ht]
	\centering
	%\includegraphics[width=50mm,scale=0.5]{img/git}
	\resizebox{.3\textwidth}{!}{\includegraphics{img/git}}
	\caption{Logo di Git}
	\label{fig:one}
\end{figure}

\section{Java}
\emph{Java} è un linguaggio di programmazione ad alto livello orientato agli oggetti.\\
Il suo scopo è quello di essere multipiattaforma, tutte le piattaforme che supportano il linguaggio devono essere in grado di eseguire un codice \emph{Java} compilato senza effettuare nuovamente la compilazione.\\
Compilando un codice \emph{Java} si ottiene un file \emph{Java ByteCode} (con estensione \texttt{.class}) che sarà eseguito sulla \emph{JVM} (Java Virtual Machine).\\
È proprio la \emph{JVM} ad essere utilizzabile sulla maggior parte delle piattaforme.\\
\begin{figure}[ht]
	\centering
	\resizebox{.1\textwidth}{!}{\includegraphics{img/java}}
	\caption{Logo di Java}
	\label{fig:one}
\end{figure}

\section{Eclipse}
\emph{Eclipse} è un IDE (Integrated Development Environment) per lo sviluppo software realizzato in Java.\\
\emph{Eclipse} unisce in un’unica interfaccia grafica per:
\begin{itemize}
	\item[$\bullet$]Scrittura del codice sorgente
	\item[$\bullet$]Compilazione
	\item[$\bullet$]Debugging
\end{itemize}
\begin{figure}[ht]
	\centering
	\resizebox{.1\textwidth}{!}{\includegraphics{img/eclipse}}
	\caption{Logo di Eclipse}
	\label{fig:one}
\end{figure}

\section{Framework Spring}
\emph{Spring} è un framework open source per lo sviluppo di applicazioni in Java.\\
\emph{Spring} è un framework modulare, consente di utilizzare solo i moduli di cui effettivamente si necessita.\\
Nello specifico, per la realizzazione del progetto sono stati utilizzati i moduli descritti in seguito.
\subsection{Spring Boot}
L’utilizzo di questo modulo consente di creare applicazioni Java standalone, pronte all’esecuzione.\\
\emph{Spring Boot} consente di scegliere quale tool utilizzare per effettuare la build, in questo progetto è stato utilizzato Maven.\\
Alla base di ogni build con \emph{Spring Boot} e \emph{Maven} c’è il file \emph{pom.xml} (acronimo di Project Object Model) in cui sono descritte tutte le impostazioni e le dipendenze necessarie alla build in un linguaggio \emph{simil-XML}.
\subsection{Spring Data}
\emph{Spring Data} fornisce un modello di programmazione per l’accesso ai dati indipendentemente dal tipo di database utilizzato.\\
Nello specifico, per la realizzazione del progetto è stata utilizzata la specifica di \emph{Spring Data} chiamata \emph{JPA} per:
\begin{itemize}
	\item[$\bullet$]Gestione del database
	\item[$\bullet$]Creazione di tabelle
	\item[$\bullet$]Esecuzione di query
\end{itemize}

\begin{figure}[ht]
	\centering
	\resizebox{.3\textwidth}{!}{\includegraphics{img/spring}}
	\caption{Logo di Spring}
	\label{fig:one}
\end{figure}


\section{Azure DevOps}
\emph{Azure DevOps} è una piattaforma fornita da Microsoft\texttrademark che consente di pianificare il lavoro, creare e distribuire applicazioni.\\
Nello specifico, per la realizzazione del progetto sono state utilizzate le applicazioni descritte in seguito:
\begin{itemize}
	\item \textbf{Azure Repos} per la creazione e la gestione di repository \emph{Git} per il controllo e il versionamento del codice sorgente.
	\item \textbf{Azure Pipelines} per l’automatizzazione del build e del deploy dell’intero progetto.
	\item \textbf{Azure Artifacts} per la condivisione degli artefatti \emph{Maven}.
\end{itemize}
\begin{figure}[ht]
	\centering
	\resizebox{.3\textwidth}{!}{\includegraphics{img/azure}}
	\caption{Logo di Azure}
	\label{fig:one}
\end{figure}
\section{Docker}
\emph{Docker} è un progetto open source per la creazione di container portabili e multipiattaforma.\\
Docker utilizza il kernel Linux per isolare i processi in modo da poterli eseguire in maniera indipendente.\\
Ogni container è basato su un’immagine, solitamente un intero Sistema Operativo, a scelta tra quelle fornite all’interno di Docker Hub (raccolta ufficiale di tutte le immagini disponibili) o un’immagine “custom”, realizzata appositamente dal singolo sviluppatore per un determinato scopo.\\
Grazie all’organizzazione in container si ha un alto livello di sicurezza, esattamente come se i sistemi in esecuzione fossero fisicamente separati.\\
Nella realizzazione del progetto è stata utilizzata l’immagine ufficiale di \emph{Kong Gateway} (approfondita nel paragrafo successivo) per la creazione del container.
\begin{figure}[ht]
	\centering
	\resizebox{.3\textwidth}{!}{\includegraphics{img/docker}}
	\caption{Logo di Docker}
	\label{fig:one}
\end{figure}

\section{Kong Gateway}
Un API gateway è uno strumento che si interpone tra un client e un back end per la gestione delle API (Application Programming Interface) che si comporta come un proxy inverso accettando tutte le richieste indirizzate alle API gestite, consentendo di configurare\emph{services} e \emph{routes}.\\
Kong Gateway è un API gateway cloud-native che fornisce tutte le caratteristiche descritte sopra e, inoltre, consente l’utilizzo di plugin.\\
Una volta installato è possibile configurarlo accedendo alle seguenti pagine:
\begin{itemize}
	\item \textbf{Kong Manager}, porta 8000, consente di utilizzare un’interfaccia grafica per configurare \emph{services}, \emph{routes} e \emph{plugins}.
	\item \textbf{Pagina delle configurazioni}, porta 8002, raccoglie tutte le configurazioni del gateway in formato JSON.
\end{itemize}
\begin{figure}[ht]
	\centering
	\resizebox{.3\textwidth}{!}{\includegraphics{img/kong}}
	\caption{Logo di Kong Gateway}
	\label{fig:one}
\end{figure}
\subsection{Service}
Un \emph{service} in Kong Gateway è un’astrazione di tutti i servizi upstream custom che si aggiungono alla configurazione. Con \emph{servizio upstream custom} si intende un microservizio custom che prende dati dalla richiesta inoltrata al gateway e ne restituisce altri al gateway stesso, che si occuperà di comunicarli al client.\\
Solitamente ad ogni \emph{service} è associato una o più \emph{routes}.\\

\subsection{Route}
Una \emph{route} è una regola definita per indirizzare correttamente le richieste del client.\\
L’associazione di una (o più) route ad un servizio consente di realizzare un meccanismo di routing molto potente, dato che è possibile configurare molto nel dettaglio il percorso che si vuole realizzare (protocolli da utilizzare, livello di sicurezza ecc.).\\

\subsection{Plugin}
Un \emph{plugin} è un’entità che sarà eseguita durante tutto il ciclo di vita di una richiesta o risposta HTTP/S (HyperText Trasfer Protocol / Secure).\\
È il modo in cui Kong Gateway fornisce la possibilità di ottenere funzionalità aggiuntive per un \emph{service} o una \emph{route}.\\
I plugin possono configurabili possono essere sia proprietari (attivabili da Kong Manager) sia custom. Per la realizzazione di un plugin custom si ha la possibilità di scegliere tra vari linguaggi di programmazione per lo sviluppo quali Go, Python, JavaScript e Lua (linguaggio utilizzato per lo sviluppo del plugin custom utilizzato nel progetto).\\ 

\subsection{Consumer}
Un \emph{consumer} in Kong Gateway può essere inteso come un utente di uno specifico servizio e può essere identificato tramite un \texttt{id} univoco.

\section{PostgreSQL}
\emph{PostgreSQL} è un DBMS (Database Management System) open source relazionale a oggetti che supporta la gran parte delle istruzioni del linguaggio SQL standard alle quali aggiunge diverse feature quali:
\begin{itemize}
	\item[$\bullet$]Query complesse
	\item[$\bullet$]Foreign keys
	\item[$\bullet$]Triggers
	\item[$\bullet$]Views aggiornabili
	\item[$\bullet$]Integrità dei dati nelle transazioni
	\item[$\bullet$]Controllo concorrente del versionamento
\end{itemize}
Inoltre fornisce la possibilità di aggiungere tipi di dato, funzioni, operatori ecc.
\begin{figure}[ht]
	\centering
	\resizebox{.4\textwidth}{!}{\includegraphics{img/postgres}}
	\caption{Logo di PostgreSQL}
	\label{fig:one}
\end{figure}

\section{Lua}
\emph{Lua} è un linguaggio di scripting open source che combina la sintassi procedurale a costrutti di dati basati su array associativi.\\
È un linguaggio tipizzato dinamicamente, viene eseguito interpretando un bytecode e gestisce la memoria in modo automatico tramite un \emph{garbage collector}.\\
È stato scelto per la realizzazione del plugin per le sue caratteristiche quali:
\begin{itemize}
	\item[$\bullet$]Velocità
	\item[$\bullet$]Portabilità
	\item[$\bullet$]Leggerezza
	\item[$\bullet$]Embed-easy
\end{itemize}
\begin{figure}[ht]
	\centering
	\resizebox{.2\textwidth}{!}{\includegraphics{img/lua}}
	\caption{Logo di Lua}
	\label{fig:one}
\end{figure}

\section{Postman}
\emph{Postman} è una piattaforma API per la creazione, sviluppo e testing di APIs.\\
Nello sviluppo del progetto è stato utilizzato per la fase di testing (approfondita nel capitolo dedicato), dato che permette di effettuare delle richieste HTTP/S, offrendo la possibilità di configurare il body della stessa e di ricevere la risposta.\\
\begin{figure}[ht]
	\centering
	\resizebox{.2\textwidth}{!}{\includegraphics{img/postman}}
	\caption{Logo di Postman}
	\label{fig:one}
\end{figure}

% \emph{MPI} cioè, Message Passing Interface, è uno \textit{standard per l'interfaccia di una libreria per lo scambio di messaggi} \cite{mpi_standard}.\\
% Questo standard \textit{de facto} è nato grazie al lavoro svolto su \textit{MPI Forum}, un forum nel quale aziende che si occupano di \textquotedblleft Parallel Computing\textquotedblright, ricercatori nell'ambito informatico, sviluppatori di librerie e di applicazioni hanno collaborato per raggiungere questo risultato.\\
% Come detto \textit{MPI} è una specifica e non una libreria e si propone quindi di imporre regole e di dare istruzioni su quello che una libreria per lo scambio di messaggi deve fare. Inoltre, non essendo \textit{MPI} un linguaggio di programmazione tutte le operazioni sono espresse come funzioni, subroutine, o metodi a seconda del \textit{binding} con i linguaggi che fanno parte dello standard.\\
% L'obbiettivo di \textit{MPI}, quindi, è quello di stabilire uno standard per il \textit{message-passing} \emph{portabile}, \emph{flessibile}, \emph{pratico} ed \emph{efficiente}.\\
% \textit{MPI} è rivolto principalmente al modello di \textit{message-passing} nella \textit{programmazione parallela}, in cui i dati vengono spostati dallo spazio di indirizzi di un processo a quello di un altro tramite operazioni cooperative su ciascun processo.\\
% In particolare in un ambiente di comunicazione a memoria distribuita, in cui le astrazioni di livello superiore sono costruite sulla base del livello inferiore, ovvero sulle routine di \textit{message-passing}, i benefici della standardizzazione sono particolarmente evidenti.\\
% Inoltre, la definizione di uno standard \textit{message-passing}, come quella proposta da MPI, fornisce un insieme di funzioni base ben definito, efficientemente implementabili dai vendor interessati al \textquotedblleft Parallel Computing\textquotedblright, o per le quali sia possibile fornire supporto hardware, rafforzando in tal modo la scalabilità.\\
% L'obiettivo di \textit{MPI} è quindi quello di sviluppare uno standard ampiamente utilizzato per la scrittura di programmi di \textit{message-passing}.

% \subsection{La struttura di un programma MPI}
% Un programma \textit{MPI} è un programma che, seguendo le procedure introdotte dallo standard, esegue operazioni di \textit{message-passing} su architetture di calcolo parallelo.\\
% D'ora in avanti si affronteranno programmi \textit{MPI} in \textit{C/C++} che utilizzano la libreria \emph{OpenMPI} \cite{open_mpi} per l'implementazione delle funzioni, ma le considerazioni fatte sono comunque valide per le relative funzioni legate al \textit{Fortran} e per implementazioni di altre librerie.\\
% Ogni programma \textit{MPI} deve utilizzare la direttiva del preprocessore: \lstinline{#include "mpi.h"}\\
% \textit{mpi.h} infatti contiene le definizioni, le macro e i prototipi delle funzioni necessari per compilare un programma \textit{MPI}.\\
% Prima di ogni altra funzione \textit{MPI} bisogna invocare la funzione \textit{MPI\_Init()}; questa funzione deve essere chiamata una sola volta. La \textit{MPI\_Init()} prende come argomenti i puntatori ai parametri del \textit{main} e permette al sistema di preparare l'ambiente per l'esecuzione delle varie routine \textit{MPI} che possono essere usate.\\
% Una volta che il programma ha finito di utilizzare le funzioni \textit{MPI} deve chiamare la \textit{MPI\_Finalize()} che permette di \textquotedblleft pulire\textquotedblright~ogni lavoro non terminato dalle varie funzioni \textit{MPI} invocate precedentemente.\\
% Nel listato \ref{lst:genic_mpi} è mostrata la generica struttura di un programma \textit{MPI} \cite{mpi_general}.\\
% \begin{lstlisting}[label={lst:genic_mpi},
% caption={Programma MPI generico}]

% (*@~ ~ ~ ~\raisebox{-1pt}[0pt][0pt]{$\vdots$}@*)

% #include (*@\textquotedblleft@*)mpi.h"

% (*@~ ~ ~ ~\raisebox{-1pt}[0pt][0pt]{$\vdots$}@*)

% main(int argc, char** argv){

% (*@~ ~ ~ ~ ~ ~ ~ ~ ~ ~{\raisebox{-1pt}[0pt][0pt]{$\vdots$}}@*)

%     //Nessuna chiamata a funzioni MPI prima di questa
%     MPI_Init(&argc, &argv);

% (*@~ ~ ~ ~ ~ ~ ~ ~ ~ ~{\raisebox{-1pt}[0pt][0pt]{$\vdots$}}@*)

%     MPI_Finalize();
%     //Nessuna chiamata a funzioni MPI dopo questa

% (*@~ ~ ~ ~ ~ ~ ~ ~ ~ ~{\raisebox{-1pt}[0pt][0pt]{$\vdots$}}@*)
% }

% \end{lstlisting}
% \subsection{Le principali componenti}\label{subsec:comm_mpi}
% In MPI la comunicazione fra i processi si basa sullo scambio di messaggi.\\
% MPI quindi definisce le strutture e le informazioni che servono per realizzare uno scambio di messaggi tra processi.\\
% In particolare lo standard descrive:
% \begin{itemize}
% 	\item In che modo rappresentare il dato, da inviare nel messaggio, durante la comunicazione;
% 	\item Come specificare i processi protagonisti dello scambio del messaggio;
% 	\item I vari modi in cui può essere implementata la comunicazione.
% \end{itemize}  
% \subsubsection{Definizione dei dati in MPI}\label{subsec:def_dati_mpi}
% Per poter inviare un dato attraverso un messaggio, che poi verrà scambiato tra i processi, occorre definire alcune informazioni fondamentali legate al dato stesso; in particolare è necessario definire:
% \begin{itemize}
% 	\item \textbf{Il buffer}, ovvero l'indirizzo di memoria che contiene i dati da inviare;
% 	\item \textbf{Il numero di elementi} da inviare nel messaggio;
% 	\item \textbf{Il tipo di dato} degli elementi.
% \end{itemize}
% Il tipo di dato può rispecchiare uno dei tipi di dato più comuni del linguaggio \textit{C} (figura \ref{fig:mpi_data_types}) oppure può essere un tipo di dato definito da utente in quanto MPI fornisce le primitive per costruire strutture dati partendo da altre già esistenti.

% \subsubsection{Specificazione dei processi coinvolti nella comunicazione}\label{subsec:comm_rank_tag}
% Durante l'invio di un messaggio è necessario specificare il destinatario e garantire che le informazioni che lo identificano siano univoche per non compromettere la comunicazione.\\
% A questo scopo durante l'invio di un messaggio MPI bisogna sempre indicare:
% \begin{itemize}
% 	\item \textbf{Il communicator} che rappresenta uno specifico contesto a cui appartiene un gruppo di processi (il \textit{communicator} di default si chiama \textit{MPI\_COMM\_WORLD} e racchiude tutti i processi disponibili).
% 	\item \textbf{Il rank}, che è un identificativo univoco assegnato ad ogni processo, del processo destinatario;
% 	\item \textbf{Il tag} che permette, grazie ad un intero definito da utente, di differenziare ulteriormente il messaggio.
% \end{itemize}

% \subsubsection{Le implementazioni delle comunicazioni punto a punto}
% MPI prevede diverse modalità per gestire la comunicazione tra i processi.
% \paragraph{La comunicazione standard}~\newline~\newline
% La modalità standard è \emph{bloccante e asincrona} si effettua utilizzando la funzioni \textit{MPI\_Send} per l'invio e \textit{MPI\_Recv} per la ricezione.\\
% \begin{lstlisting}[label={lst:mpi_send_recv},
% caption={Intestazioni delle primitive di comunicazione MPI}]
% MPI_Send(void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)
         
% MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status)
% \end{lstlisting}

% In entrambe le funzioni i parametri \textit{buf}, \textit{count} e \textit{datatype} servono per fornire le informazioni sul contenuto nel messaggio come spiegato nel paragrafo \ref{subsec:def_dati_mpi}.\\
% Il parametro \textit{dest} nella funzione di invio e il parametro \textit{source} in quella di ricezione indicano rispettivamente il \textit{rank} del processo che deve ricevere e di quello che deve inviare i dati. Oltre al \textit{rank} dei processi coinvolti, queste funzioni prendono in argomento anche le altre informazioni illustrate nel paragrafo \ref{subsec:comm_rank_tag} relative al destinatario; in particolare richiedono: il \textit{tag} del messaggio e il \textit{communicator(comm)} nel quale si svolge la comunicazione.\\
% La funzione \textit{MPI\_Recv} grazie a \textit{status} può ottenere informazioni aggiuntive sul messaggio.\\
% Essendo la \textit{MPI\_Send} bloccante, ritorna solo quando i dati sono stati copiati nel buffer di sistema del destinatario e quindi, per esempio, se il buffer è pieno, la funzione resta bloccata in attesa che si liberi. Una volta che la funzione è ritornata, non c’è alcuna garanzia che il processo destinatario abbia ricevuto il messaggio.\\
% A sua volta la \textit{MPI\_Recv}, essendo bloccante ritorna solamente quando i dati sono stati copiati dal buffer di sistema all’indirizzo di memoria specificato.\\
% Lo schema di una comunicazione bloccante è mostrato in figura \ref{fig:mpi_block_com}.
% \paragraph{Altri tipi di comunicazione punto a punto}~\newline~\newline
% Oltre alla modalità standard (asincrona) MPI definisce altre modalità, \textit{bloccanti e non}, di comunicazione per l’invio di un messaggio.\\
% Le seguenti modalità di invio sono \emph{bloccanti} e richiedono come parametri gli stessi richiesti dalla funzione primitiva MPI\_Send:
% \begin{itemize}
% 	\item MPI\_Ssend ($\cdots$): questa funzione ritorna solo quando il destinatario ha iniziato a ricevere;
% 	\item MPI\_Bsend ($\cdots$): questa funzione ritorna quando i dati sono copiati in un buffer specifico;
% 	\item MPI\_Rsend ($\cdots$): da utilizzare solo quando si è certi che il destinatario sia in ascolto.
% \end{itemize}
% Esistono anche modalità di comunicazione \emph{non bloccanti} (di cui viene mostrato lo schema in figura \ref{fig:mpi_non_block_comm}) che vengono descritte dalle seguenti funzioni nel codice \ref{lst:mpi_send_recv_non_blocc}.\\
% \begin{lstlisting}[ 
% label={lst:mpi_send_recv_non_blocc},
% caption={Intestazioni delle comunicazioni non bloccanti MPI}]
% MPI_Isend(void* buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm, MPI_Request &request)

% MPI_Irecv(void* buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Request &request)
% \end{lstlisting}
% Le funzioni sopracitate ritornano immediatamente, ma la memoria all’indirizzo \textit{buf} non può essere scritta o letta finché non si è certi della conclusione dell’operazione.\\
% Il campo \textit{request} delle due funzioni è un \textit{handle} che permette di verificare e interagire con lo status della richiesta grazie ad opportune funzioni (MPI\_Test e MPI\_Wait).

% \subsubsection{Le comunicazioni collettive}\label{subsubsec:coll_comm}
% Un ultimo tipo di comunicazione messo a disposizione da MPI è la comunicazione collettiva. Una comunicazione collettiva è una comunicazione che riguarda tutti i processi presenti all'interno di uno stesso \textit{communicator} che non interferisce con le comunicazioni \emph{punto-punto} e che non può essere bloccante.\\
% MPI mette a disposizione diverse funzioni per gestire vari tipi di comunicazione collettiva (figura \ref{fig:mpi_collect_comm}):
% \begin{itemize}
% \item \textbf{MPI\_Bcast} per permettere ad un processo di inviare lo stesso messaggio a tutti gli altri;
% \item \textbf{MPI\_Reduce} per permettere ad un processo di suddividere un messaggio tra tutti gli altri;
% \item \textbf{MPI\_Scatter} per far si che tutti i processi inviino un messaggio ad uno stesso nodo;
% \item \textbf{MPI\_Gather} per far si che tutti i processi cooperino per calcolare un risultato da inviare ad uno stesso processo.
% \end{itemize}


% \subsection{Il modello hardware per un ambiente MPI}\label{subsubsec:mpi_hw_model}
% Come detto MPI è un'interfaccia per le librerie che si devono occupare di message-passing.\\
% Questo scambio di informazioni è dunque legato ad un ambiente di calcolo parallelo e a una relativa architettura hardware che consente di eseguire uno stesso programma parallelamente su più processori o addirittura su più nodi.\\
% Le varie configurazioni che può avere un ambiente di calcolo parallelo, secondo la tassonomia di Flynn (1986), derivano dalla configurazione hardware e software di due componenti principali del sistema: il \emph{flusso di istruzioni (processi)} e il \emph{flusso di dati}. Le varie configurazioni previste da questa suddivisione sono:
% \begin{itemize}
% 	\item \textbf{SISD} (\textit{Single Instruction Single Data}): Architetture dei sistemi seriali, senza quindi, nessun grado di parallelismo (schema in figura \ref{fig:sisd});
% 	\item \textbf{SIMD} (\textit{Single Instruction Multiple Data}): Architetture composte da molte unità di elaborazione che eseguono contemporaneamente la stessa istruzione ma lavorano su insiemi di dati diversi (schema in figura \ref{fig:simd});
% 	\item \textbf{MISD} (\textit{Multiple Instruction Single Data}): Architetture in cui più flussi di istruzioni lavorano contemporaneamente su un unico flusso di dati (schema in figura \ref{fig:misd}). Questa tipologia di architettura non è stata praticamente mai adottata;
% 	\item \textbf{MIMD} (\textit{Multiple Instruction Multiple Data}): Architetture in cui più istruzioni vengono eseguite contemporaneamente su più dati diversi (schema in figura \ref{fig:mimd}). Sotto questa classificazione ricadono i \textit{cluster} di computer e di conseguenza l'ambiente sul quale è stato basato lo sviluppo di questa tesi.
% \end{itemize}

% In particolare tra i sistemi MIMD possono distinguersi le architetture a \emph{memoria condivisa} (figura \ref{fig:mem_dist}) o quelle a \emph{memoria distribuita} (figura \ref{fig:mem_cond}).\\
% Nella prima configurazione la memoria è condivisa fisicamente (UMA) o solo logicamente assegnando indirizzi globali alle vari memorie locali (NUMA), permettendo ai vari nodi di lavorare sugli stessi spazi di memoria, evitando quindi di dover gestire le comunicazioni.\\
% Nell'architettura a memoria distribuita, ogni nodo possiede una propria memoria locale che non fa parte dello spazio di indirizzamento degli altri processori e, per regolare l'accesso di un nodo alle risorse che non sono locali, bisogna utilizzare protocolli di comunicazione e scambio dati come, per esempio, quelli descritti da MPI.